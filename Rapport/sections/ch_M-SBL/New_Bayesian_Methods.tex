%As described in section \ref{sec:sol_met} the covariance-domain dictionary learning (Cov-DL) is not a fitted method to use in the recovering of the source matrix $\mathbf{X}$ as the found source matrix is not the true recovering. 
%Instead a different method, multiple sparse Bayesian Learning (M-SBL), is used for the recovering process of the last element of the multiple measurement model (MMV) \ref{eq:MMV_model}.
In this chapter the Multiple sparse Bayesian Learning (M-SBL) method is described in details. As the method leverage a bayesian framework the generel conpect of Bayesian inference is shortly introduced prior to the the M-SBL method, with respect to the model of interest. The chapter is inspired by \cite{phd_wipf} and the articles \cite{article_wipf}, \cite{Balkan2014}.

Consider again the MMV model for a non-segmented case of EEG-measurements
\begin{align*}
\mathbf{Y} = \mathbf{AX} + \mathbf{E},
\end{align*}
with measurement matrix $\mathbf{Y} \in \mathbb{R}^{M \times L}$, sources matrix $\mathbf{X} \in \mathbb{R}^{N \times L}$ and mixing matrix $\mathbf{A} \in \mathbb{R}^{M \times N}$. Note that $\textbf{A}$ is known throughout the chapter, as it was found by Cov-DL in chapter \ref{ch:Cov-DL}.

The aim is to recover $\textbf{X}$ in the case of fewer measurements than active sources, $k>M$. In \cite{Balkan2014} is proven that exact localization of the active sources can be achieved by M-SBL for $k>M$, when two sufficient conditions satisfied.   
\todo{skal de sidster her med ellers skal det specificeres en lille smule}The basic approach is to find the support set $S$ of $\textbf{X}$ providing the non-zeros rows of $\mathbf{X}$ which corresponds to localization of the active sources. The support set $S$ is constructed from a minimisation of a log-likelihood function defined from Bayesian framework.

\section{Bayesian Inference}
Bayesian probability differs from the classical probability(\textit{the frequentist, relative
frequency with which A occurs}) by interpreting probability as reasonable expectation. 
In general the Bayesian framework builds upon the task of inferring what the model parameters most be, given the model and data.  
%%% jeg forstår ikke helt sammenhængen her
%From Bayesian inference theory a posterior distribution is constructed to predict a new distribution of an unknown data sample such that a distribution of the unknown samples are returned. The optimum sample estimate of a parameter -- for the posterior distribution -- can be found by e.g. maximum a posterior (MAP) estimation \todo{Kilde (WIKI): This has the disadvantage that it does not account for any uncertainty in the value of the parameter, and hence will underestimate the variance of the predictive distribution}.
%%%
This is centred around Bayes' theorem from which the posterior distribution of some unobserved variables $\textbf{C}$ given some observed variables $\textbf{B}$
\begin{align*}
p(\textbf{C}|\textbf{B})=\frac{p(\textbf{B}|\textbf{C})p(\textbf{C})}{p(\textbf{B})}
\end{align*}  
where $p(\textbf{B}|\textbf{C})$ is the probability density function of $\text{B}$ given $\text{C}$, also referred to as the likelihood function of $\text{C}$(?), $p(\text{C})$ is a prior distribution of $\text{C}$ and $p(\text{B})$ is the distribution of $\text{B}$ serving as a normalizing parameter.  
By maximizing the posterior distribution with respect to $\textbf{C}$ the maximum a posteriori (MAP) estimate is achieved. 
\begin{align*}
\textbf{C}_{MAP} = \arg \max_{\mathbf{C}} \frac{p(\mathbf{B} \vert \mathbf{C}) p(\mathbf{C})}{p(\mathbf{B)}}
\end{align*}
That is the estimate of $\textbf{C}$ with the highest probability of causing the given variables $\textbf{B}$. 
%% go to our case 

Consider the current MMV model, where we want to estimate the model parameter/source matrix $\textbf{X}$ given the measurements $\textbf{Y}$.   
  
%%%%%% kan dette pilles ud?
%With the knowledge of $\mathbf{A}$ and $\mathbf{Y}$ it is possible to find maximum likelihood estimate of $\textbf{X}$. 
%By maximising the likelihood $p(\mathbf{Y} \vert \mathbf{X})$ an estimate of $\mathbf{X}$ can be achieved in the case of more sensors than sources, $M > N$. 
%But in the desired case where $M < N$ the estimation becomes complicate as the MMV model becomes under-determined and potentially an infinitely number of solutions exist with equal likelihoods.
%As the optimisation problem of the MMV model is NP-hard another estimation method must be used.
%%%%%%

In the desired case where $M < N$ the MMV model makes an under-determined system and potentially an infinitely number of solutions exist with equal likelihoods.  
Within this Bayesian framework the source matrix $\mathbf{X}$ can be seen as a variable which is drawn from some distribution $p(\mathbf{X})$, as such it is possible to narrow down the infinitely solution space. 
Assuming a prior belief that $\textbf{Y}$ is generated from a sparse source matrix, gives a so-called sparsity inducing prior. That is $\textbf{X}$ is drawn from a distribution which has a sharp, possibly infinite, spike at zero surrounded by fat tails.
Now estimation of $\textbf{X}$ from the MMV model can be view as the following MAP estimation task\cite[p. 14]{phd_wipf} 
%\begin{align*}
%\hat{\mathbf{X}} &= \arg \max_{\mathbf{X}} p(\mathbf{Y} \vert \mathbf{X}) p(\mathbf{X}) \\
%&= \arg \max_{\mathbf{X}} \frac{p(\mathbf{Y} \vert \mathbf{X}) p(\mathbf{X})}{p(\mathbf{Y)}} \quad (\text{Bayers Formular}) \\
%&= \arg \max_{\mathbf{X}} p(\mathbf{X} \vert \mathbf{Y}).
%\end{align*}
\begin{align*}
\hat{\mathbf{X}} &= \arg \max_{\mathbf{X}} \frac{p(\mathbf{Y} \vert \mathbf{X}) p(\mathbf{X})}{p(\mathbf{Y)}}.
\end{align*}
with a prior distribution $p(\mathbf{X}) \propto \exp \left( - \Vert \mathbf{X} \Vert_0\right)$\todo{vi skal da have exp her ikke, jo støtte 0-norm for mindre sandsynlighed, og kan vi nøjes med den ene linje ovenfor?}.

Different MAP estimation approaches exists separated by the choice of sparsity inducing prior and optimization method. 
However, regardless of the approach some problems have shown to occur when using a fixed and algorithm-dependent prior. One issue is the posterior not being sparse enough if a prior is not as sparse, leading to non-recovery. 
Another issue is that a combinatorial number of suboptimal local solutions can occur.
By use of automatic relevance determination (ARD) the problems related to the fixed sparse prior can be avoided\cite[p. 20]{phd_wipf}. 
ARD is a method where a prior is introduced to determine the relevance of a parameter. The main asset of this alternative approach is the use of an empirical prior. That is an flexible prior distribution which depends on an unknown set of hyperparameters, which is to be learned from the data
\todo{citat: p. 9(pdf) sparse Bayesian learning (SBL) is an empirical Bayesian approaches, which use a parameterized prior to encourage sparsity through a process called evidence maximization}. 
\subsection{Empirical Bayesian Estimation}
%% nødvendigt i forhold til ovenstående?
%This prior is modulated by a vector of hyperparameters affecting the prior variance of each row in $\mathbf{X}$.
%This can also be view as a regularisation of the solution space which is narrowed to consist only of relevant information \cite{ARD}.
%An empirical prior can be used with ARD as the empirical prior is flexible and depends on the unknown hyperparameter $\boldsymbol{\gamma}$ and therefore more data-dependent -- such prior can be controlled to induce sparsity.
Let the likelihood function $p(\mathbf{Y} \vert \mathbf{X})$ be Gaussian, with known noise variance $\sigma^2$\todo{skal dette begrundes? det stammer fra det ordiginale optimeringsproblem recast in bayesian terms (I.10) i pdf}. 
Then for each column in $\mathbf{Y}$ and $\mathbf{X}$ the likelihood is written as
\begin{align*}
p(\mathbf{y}_{j} \vert \mathbf{x}_{j}) &= \mathcal{N}(\mathbf{Ax}_{j}, \sigma^2 \mathbf{I}) \\
&= (2 \pi \sigma^2)^{-N/2} \exp \left( - \frac{1}{2 \sigma^2} \Vert \mathbf{y}_{j} - \mathbf{A} \mathbf{x}_{j} \Vert_2^2 \right).
\end{align*}
The empirical prior is now defined by application of ARD. 
The $i$-th row of the source matrix $\mathbf{X}$, $\mathbf{x}_{i \cdot}$, is assigned an $L$-dimensional independent Gaussian prior with zero mean and a variance controlled by an unknown hyperparameter $\gamma_i$\todo{stemmer i på hyper her? se phd, evt. fed hyper med i på}:
\begin{align*}
p (\mathbf{x}_{i \cdot} ; \gamma_i) &= \mathcal{N}(0, \gamma_i \mathbf{I}).
\end{align*}
By combing the row priors
\begin{align*}
p (\mathbf{X} ; \boldsymbol{\gamma}) &= \prod_{j=1}^L p (\mathbf{x}_{i \cdot} ; \gamma_i),
\end{align*}
a full prior of $\mathbf{X}$ is achieved modulated by the hyperparameter vector(matrix?) $\boldsymbol{\gamma} = [\gamma_1, \dots, \gamma_L]^T$. 
By combining the full prior and the likelihood $p(\mathbf{y}_{j} \vert \mathbf{x}_{j})$ the posterior of the $j$-th column of the source matrix $\mathbf{X}$ becomes\todo{bør dette ikke være hele X, eller i så fald vel hyper i?}
\begin{align*}
p(\mathbf{x}_{j} \vert \mathbf{y}_{j} ; \boldsymbol{\gamma}) = \frac{p(\mathbf{x}_{j}, \mathbf{y}_{j} ; \boldsymbol{\gamma})}{\int p(\mathbf{x}_{j}, \mathbf{y}_{j} ; \boldsymbol{\gamma}) \ d \mathbf{x}_{j}} = \mathcal{N}(\boldsymbol{\mu}_{j}, \boldsymbol{\Sigma}),
\end{align*}
with mean and covariance given as
\begin{align}
\boldsymbol{\Sigma} &= \text{Cov}(\mathbf{x}_{j} \vert \mathbf{y}_{j} ; \boldsymbol{\gamma}) = \boldsymbol{\Gamma} - \boldsymbol{\Gamma} \mathbf{A}^T \boldsymbol{\Sigma}_y^{-1} \mathbf{A} \boldsymbol{\Gamma}, \quad \forall j = 1, \dots, L \nonumber \\
\mathcal{M} &= [\boldsymbol{\mu}_{1 \cdot}, \dots, \boldsymbol{\mu}_{ L \cdot}] = \mathbb{E}[\mathbf{X} \vert \mathbf{Y} ; \boldsymbol{\gamma}] = \boldsymbol{\Gamma} \mathbf{A}^T \boldsymbol{\Sigma}_y^{-1} \mathbf{Y}, \label{eq:moments}
\end{align}
where $\boldsymbol{\Gamma} = \text{diag}(\boldsymbol{\gamma})$ and $\boldsymbol{\Sigma}_y = \sigma^2 \mathbf{I} + \mathbf{A} \boldsymbol{\Gamma} \mathbf{A}^T$ \todo{Er det nemt at se at de to sigmaer vi bruger ikke er den samme? Den ene er en kovarianse mens den anden er en variable}. 
Let the posterior mean $\mathcal{M}$ serve as the point estimate for $\mathbf{X}$ without involving the support set $S$.
It is clear that row sparsity is achieved whenever $\gamma_i = 0$. 
From this the posterior must satisfy the following 
\begin{align*}
P(\mathbf{x}_{i \cdot} = \mathbf{0} \vert \mathbf{Y} ; \gamma_i = 0) = 1,
\end{align*}
which ensure that the posterior mean $\mathcal{M}$ of the $i$-th row, $\boldsymbol{\mu}_{i \cdot}$, will be zero\todo{her stemmer hyper i ikke den først beskrevet beskrivet, da den her bør være en constant, men vi har den som en vektor }.

From this it is evident that for estimating the support set of $\textbf{X}$ it is sufficient to estimate the hyperparameters $\gamma_i$, from which the support set can be extracted. Further the point/value estimate is of $\textbf{X}$ is given by $\mathcal{M}$\cite[p. 147/21?]{phd_wipf}\todo{ to kilder er blandet sammen..trine}. 
This leads to the actual M-SBL algorithm.

\subsection*{M-SBL for estimation of $\textbf{X}$}
Each different hyperparameter $\boldsymbol{\gamma}$ correspond to different hypothesis for the prior distribution of the underlying generation of $\mathbf{Y}$\todo{forstår ikke helt hypotese delen her}. Therefore the determination of $\boldsymbol{\gamma}$ is seen as a model selection.
Due to the empirical Bayesian strategy the unknown weights, making the source matrix $\textbf{X}$ are integrated out as follows.
By integrating the likelihood of $\textbf{Y}$ with respect to the unknown sources $\mathbf{X}$ the marginal likelihood of the observed mixed data $\mathbf{Y}$ is achieved as $p (\mathbf{Y} ; \boldsymbol{\gamma})$ \cite[p. 146]{phd_wipf}. 
By applying the $-2 \log (\cdot)$ transformation the marginal likelihood function is transformed to a cost function
\begin{align*}
\ell(\boldsymbol{\gamma}) &= -2 \log \left( \int p (\mathbf{Y}  \vert \mathbf{X}) p (\mathbf{X} ; \boldsymbol{\gamma}) \ d\mathbf{X} \right) \\
&= - 2 \log(p (\mathbf{Y} ; \boldsymbol{\gamma}))\\
&= \log ( \vert \boldsymbol{\Sigma}_y \vert) + \frac{1}{L} \sum_{j=1}^L \mathbf{y}_{j}^T \boldsymbol{\Sigma}_y ^{-1} \mathbf{y}_{j}
\end{align*}
To minimise the marginal log likelihood $\ell(\boldsymbol{\gamma})$ with respect to $\boldsymbol{\gamma}$ the expectation maximisation (EM) \todo{Tjek lige om det er evidence eller expectation} algorithm can be used. 
The E-step of the EM algorithm is to compute the posterior moments using \eqref{eq:moments} while the M-step is the following update rule of $\gamma_i$:
\begin{align*}
\gamma_i^{(k+1)} = \frac{1}{L} \Vert \boldsymbol{\mu}_{i \cdot} \Vert_2^2 + \Sigma_{ii}, \quad \forall i = 1, \dots, M.
\end{align*}
The M-step is very slow on large data. 
Instead one could use a fixed point update to fasten the convergence on large data, however convergence is no longer ensured. 
The fixed point updating step is achieved by taking the derivative of the marginal log likelihood $\ell(\boldsymbol{\gamma})$ with respect to $\boldsymbol{\gamma}$ and equating it with zero. 
This lead to the following update equation which can replace the above M-step in the EM-algorithm:
\begin{align*}
\gamma_i^{(k+1)} = \frac{\frac{1}{L} \Vert \boldsymbol{\mu}_{i \cdot} \Vert_2^2}{1 - \gamma_i^{-1 (k)} \Sigma_{ii}}, \quad \forall i = 1, \dots, M.
\end{align*}
Empirically this alternative update rule have shown use full in highly under-determined large scale cases by driving many hyper parameters toward zero allowing for the corresponding weight in the source matrix to be discarded. 
For simultaneous sparse approximation problems this is the process referred to as multiple sparse Bayesian learning, M-SBL.
From the resulting $\boldsymbol{\gamma}^\ast$ the support set $S$ of the source matrix $\textbf{X}$ can be extracted, 
\begin{align*}
S = \{ i \vert \hat{\gamma}_i \neq 0 \},
\end{align*}
concluding the localisation of active sources within $\textbf{X}$. 
In practise some arbitrary small threshold can be used such that that any sufficiently small hyperparameter is discarded.
For identification of the active sources the estimate of the source matrix $\textbf{X}$ is given as $\textbf{X}^\ast=\mathcal{M}^\ast \approx \textbf{X}$, with $\mathcal{M}^\ast = \mathbb{E}[\textbf{X}\vert \textbf{Y};\boldsymbol{\gamma}^\ast]$. 
This leads to the following estimate  
\begin{align*}
\mathbf{X}^\ast = 
\begin{cases}
\mathbf{x}_{i\cdot} = \boldsymbol{\mu}_{i \cdot}^\ast, & i \in S \\
\mathbf{x}_{i\cdot} = \mathbf{0}, & i \not \in S
\end{cases}
\end{align*}
\todo{mangler vi at klar lægge de sufficient conditions som O-balkan fandt for k>M, alt det første var vel ikke ham1}

\begin{algorithm}[H]
\caption{M-SBL}
\begin{algorithmic}[1]
\Procedure{M-SBL}{$\textbf{Y}, \textbf{A}, $ iterations}
\State $\boldsymbol{\gamma} = \mathbf{1} \in \mathbb{R}^{\text{iterations} + 2 \times N \times 1}$
\State $k = 0$
\While{$\boldsymbol{\gamma} \geq 10^{-16}$} 
	\State $\boldsymbol{\Gamma} = \text{diag}(\boldsymbol{\gamma}^k)$
	\For{$i = 1, \dots, N$}
		\State $\boldsymbol{\Sigma} = \boldsymbol{\Gamma} - \boldsymbol{\Gamma} \mathbf{A}^T \boldsymbol{\Sigma}_y^{-1} \mathbf{A} \boldsymbol{\Gamma}$
		\State $\mathcal{M} = \boldsymbol{\Gamma} \mathbf{A}^T \boldsymbol{\Sigma}_y^{-1} \mathbf{Y}$
		\State $\gamma_i^{(k+1)} = \dfrac{\frac{1}{L} \Vert \boldsymbol{\mu}_{i \cdot} \Vert_2^2}{1 - \gamma_i^{-1 (k)} \Sigma_{ii}}$
	\EndFor
	\If{$k =$ iterations}
		\State Break
	\EndIf
	\State $k += 1$
\EndWhile
\State Return $\mathcal{M}^\ast, \boldsymbol{\gamma}^\ast$
\EndProcedure
\Procedure{Support}{$\mathcal{M}^\ast, \boldsymbol{\gamma}^\ast$, non\_zero}
\State Support = $\mathbf{0} \in \mathbb{R}^{\text{non\_zero}}$
\State $\boldsymbol{\gamma}_{\text{value}} = \boldsymbol{\gamma}^\ast (-2)$
\For{$j$ in range(non\_zero)}	
	\If{$\boldsymbol{\gamma}_{\text{value}} (\arg \max (\boldsymbol{\gamma}_{\text{value}}))$ != $0$}
		\State Support($j$) = $\arg \max (\boldsymbol{\gamma}_{\text{value}}$)
		\State $\boldsymbol{\gamma}_{\text{value}}(\arg \max (\boldsymbol{\gamma}_{\text{value}})) = 0$
	\EndIf

\EndFor
\State $\mathbf{X} = \mathbf{0} \in \mathbb{R}^{N \times L-2}$
\For{$i$ in Support}
	\State $\mathbf{X}(i) = \mathcal{M}^\ast(-1)(i)$
\EndFor
\State Return $\mathbf{X}$
\EndProcedure
\end{algorithmic}
\end{algorithm}