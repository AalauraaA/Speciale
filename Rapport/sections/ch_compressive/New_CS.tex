\section{System of Linear Equations}\label{sec:SMV}
Let $\mathbf{y} \in \mathbb{R}^M$ be some vector. By basic linear algebra $\mathbf{y}$ can always be described as a linear combination of a coefficient matrix $\mathbf{A} \in \mathbb{R}^{M \times N}$ and some scalar vector $\mathbf{x} \in \mathbb{R}^N$ such that
\begin{align}\label{eq:SMV_model}
\mathbf{y} = \mathbf{Ax}.
\end{align}
Let $\mathbf{y}$ and $\mathbf{A}$ be known, then  
\ref{eq:SMV_model} makes a system of $M$ linear equations with $N$ unknowns, referred to as a linear system. 

To solve the linear system \ref{eq:SMV_model} with respect to $\textbf{x}$ one must look at the three different cases that can occur, depending on the relation between the number of linear equations $M$ and the number of unknowns $N$.
For $M = N$, the system has one unique solution, provided that a solution exist.  
If the square coefficient matrix $\mathbf{A}$ has full rank the solution can be found simply by inverting $\mathbf{A}$.
\begin{align*}
\mathbf{x} = \mathbf{A}^{-1} \mathbf{y}.
\end{align*}
For $M > N$ the system is over-determined, having more equations than unknown. There is not always a solution to an over-determined system.   
For $M < N$ the system is under-determined, having fewer equations than unknowns. There exists infinitely many solutions to an under-determined system, provided that one solution exist \cite[p. ix]{CS}.  

Consider now $\mathbf{y} \in \mathbb{R}^M$ as the observed measurements provided by $M$ EEG sensors at time $t$. 
The linear system \ref{eq:SMV_model} is then considered as a single measurement vector (SMV) model.  
Modelling the EEG measurements by the SMV model embody the following interpretations, based on chapter \ref{ch:motivation}.
Remember that EEG measurements basically are a mixture of original brain signals affected by volume conduction and noise.
The vector $\mathbf{x}$ is seen as the original source signals, with each entry representing the signal of one source. 
Thus, $\mathbf{x} \in \mathbb{R}^N$ is referred to as the source vector. 
$N$ is considered the maximum number of sources, however zero entries may occur. 
Let $k$ denote the number of non-zero entries in $\mathbf{x}$, referred to as the active sources at time $t$.   
The coefficient matrix $\mathbf{A}$, referred to as the mixing matrix, models the volume conduction and noise by mapping the source vector from $\mathbb{R}^N$ to $\mathbb{R}^M$.            

\section{Multiple Measurement Vector Model of EEG}\label{sec:MMV}
In practice EEG measurements are sampled over time by a certain sample frequency. 
Thus multiple EEG measurement vectors are achieved.
Let $L$ represent the total number of samples. 
The SMV model is now expanded to include $L$ measurement vectors and noise:
\begin{align}\label{eq:MMV_model}
\mathbf{Y} = \mathbf{AX}+\textbf{E}.
\end{align}
$\mathbf{Y} \in \mathbb{R}^{M \times L}$ is the observed measurement matrix, $\mathbf{X} \in \mathbb{R}^{N \times L}$ is the source matrix, and $\mathbf{A} \in \mathbb{R}^{M \times N}$ is the mixing matrix. 
Furthermore, $\mathbf{E} \in \mathbb{R}^{M \times L}$ is an additional noise matrix, to be expected from psychical measurements.  
The model is now referred to as the multiple measurement vector (MMV) model.
As for \eqref{eq:SMV_model} the solution set of the linear system \eqref{eq:MMV_model} depends on the relation between $N$ and $M$ \cite[p. 42]{CS}. 

As specified in chapter \ref{ch:motivation} it the case of more sources than sensors, $M<N$, that is of interest in this thesis.  

\subsection{Segmentation}\label{seg_segmentation}
In chapter \ref{ch:motivation} it is argued that EEG measurements are only stationary within small segments. 
Hence, the following segmentation is considered.

Let $f$ be the sample frequency of the observed EEG measurement matrix $\mathbf{Y}$, and let $t$ be the length of a time interval in seconds determining the duration of one segment. 
Here $s$ is the segment index. 
As such the observed EEG measurement matrix $\mathbf{Y}$ can be divided into stationary segments $\mathbf{Y}_s \in \mathbb{R}^{M \times L_{s}}$, possibly overlapping, where $L_s = t \cdot f$ is the number of samples within one segment. 
For each segment the MMV model \eqref{eq:MMV_model} holds and is rewritten into
\begin{align}\label{eq:MMV_seg}
\mathbf{Y}_s = \textbf{A}_s\mathbf{X}_s + \textbf{E}_s, \quad \forall s.
\end{align}
Based on the assumption that each segment is stationary, it is assumed that each source signal remains either active or non-active throughout the segment.
Thus, $\mathbf{X}_s$, consists of $k$ non-zero rows -- the active sources.
Note that the mixing matrix $\textbf{A}$ is not segmented in the same manner as $\textbf{Y}$ and $\textbf{X}$, as the size of $\textbf{A}$ do not change relative to the number of segments. $\textbf{A}_s\in \mathbb{R}^{M\times N}$ is the mixing matrix that corresponds to $\textbf{X}_s$, $\textbf{Y}_s$ and $\textbf{E}_s$\todo{LÆS: note om $\textbf{A}_s$}.

In order to characterize the source matrix with respect to the number of non-zero rows, the term row sparseness is considered. 
Let the support $\text{supp}(\mathbf{X})$ denote the index set of non-zero rows of $\mathbf{X}$.
To count the non-zero rows of a matrix the $\ell_0$-norm is defined 
\begin{align*}
\Vert \mathbf{X} \Vert_0 := \text{card}(\text{supp}(\mathbf{X})),
\end{align*}
where the function $\text{card}(\cdot)$ gives the cardinality of the input set. The segmented source matrix $\textbf{X}_s$ is said to be $p$-sparse if it contains at most $p$ non-zeros rows:
\begin{align*}
\Vert \mathbf{X}_s \Vert_0 \leq p.
\end{align*}
With respect to the model the non-zero rows of the sources matrix makes the active source signals. Define  
\begin{align*}
k := \Vert \mathbf{X}_s \Vert_0
\end{align*} 
as the number of active source signals within $\textbf{X}_s$, this implies that $k\leq N$. \todo{LÆS: ny første definition af k }

\section{Solution Method}\label{sec:sol_met}
A MMV model for EEG measurements is now established.
From the model the aim is to recover the source matrix $\mathbf{X}_s$ for all segments, given only $\textbf{Y}_s$.
This gives an estimate of the original source signals from the brain as intended by the problem statement. 
In this section the solution method is presented and discussed, based on the state of the art methods lightly presented in section \ref{sec:relatedwork}. This will outline the remaining chapters of the thesis. 

Due to the problem statement the case of interest is when $M < N$, typically resulting from low density EEG measurements.  
Thus, $\mathbf{X}$ has to be recovered from an under-determined linear system. 
Hence, the solution must be found in the infinite solution space, provided that one solution exists, thus simple linear algebra can not be used. 
Alternatively, numerical methods can be considered. By mathematical optimization it is possible to restrict the solution by some constraint, and then find the unique optimal solution with respect to some cost function and the corresponding constraints.
The theory of compressive sensing provides a framework for solving an under-determined system when $\mathbf{X}$ is known to have zero rows, thus row spareness. 
Specifically a unique solution $\mathbf{X}$ can be found when $\mathbf{X}$ is $M$-sparse, cf. theorem \ref{th:CS_A} in appendix \ref{app_sec:CS}. 
When the mixing matrix $\mathbf{A}$ is unknown, as in this current case, the concept of dictionary learning can be used to determine $\mathbf{A}$, still under the assumption that $\mathbf{X}$ is $M$-sparse.  

The assumption of $\textbf{X}$ being $M$-sparse corresponds to the number of active sources $k\leq M$. However, from chapter \ref{ch:motivation} it can not be justified to apply this assumption on low density EEG measurements. Hence, the theory of compressive sensing can not be applied directly on the established model, when $M<N$.     

A method to overcome this limitation of compressive sensing, is the covariance domain dictionary learning (Cov-DL) method \cite{Balkan2015}, introduced in chapter \ref{ch:motivation}.

The method leverage the increased dimensionality of the covariance domain in order to allow the theory of compressive sensing to apply to an under-determined system. 
Note that this method only applies to the process of learning $\mathbf{A}$, in the case where $\textbf{X}$ is not $M$-sparse. 
Hence, a different approach is necessary to recover $\mathbf{X}$.

For recovering $\mathbf{X}$, given both $\mathbf{Y}$ and $\mathbf{A}$ where $M<N$ and $k\leq N$, the method multiple sparse Bayesian learning (M-SBL)\cite{Balkan2014}, introduced in chapter \ref{ch:motivation}, is considered.
This method takes advantage of the Bayesian statistic framework. Here, an empirical Bayesian estimation of $\textbf{X}$ is performed, based on the prior distribution of $\textbf{X}$ being defined by a data dependent hyper parameter.  

Combining the two methods allows recovery of $\mathbf{A}$ and $\mathbf{X}$ given low density EEG measurements $\mathbf{Y}$\cite{phd2015}. In the following two chapters each method is studied extensively, with the purpose of proposing the main algorithm in chapter \ref{ch:implementation}. 





