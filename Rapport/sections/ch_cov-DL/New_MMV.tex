\section{Dictionary Learning}\label{sec:dictionarylearning}
As clarified from the proof of theorem \ref{th:CS_A} the choice of the mixing matrix $\mathbf{A}$ is essential to achieve the best recovery of the sparse source vector $\mathbf{x}$ from the EEG measurement $\mathbf{y}$. 
For the estimation one could choose a dictionary as choice for the mixing matrix $\mathbf{A}$ \todo{Skriv kort om hvad dictionary er og g√∏r}.

Pre-constructed dictionaries do exist which in many cases results in simple and fast algorithms for reconstruction of $\mathbf{x}$ \cite{Elad_book}. 
Pre-constructed dictionaries are typically fitted to a specific kind of data. 
For instance the discrete Fourier transform or the discrete wavelet transform are used especially for sparse representation of images \cite{Elad_book}. 
Hence the results of using such dictionaries depend on how well they fit the data of interest, which is creating a certain limitation. 
An alternative is to consider an adaptive dictionary based on a set of training data that resembles the data of interest. 
For this purpose learning methods are considered to empirically construct a fixed dictionary which can take part in the application. 
There exist different type of dictionary learning algorithms. One is the K-SVD which is to be elaborated in this section. The K-SVD algorithm was presented in 2006 by Elad et al. and found to outperform pre-constructed dictionaries when computational cost is of secondary interest \cite{Elad2006}. 

For the K-SVD algorithm several measurements vectors $\mathbf{y}$ must used to learn the dictionary $\mathbf{A}$. Therefore, the K-SVD algorithm will be used on the MMV model as described in \eqref{eq:MMV_model}.

